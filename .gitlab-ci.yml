# GitLab CI/CD Pipeline for robotframework-chat
# Works with shell executor on any OS (macOS, Linux)
# Assumes tools are pre-installed on runner
#
# Three pipeline modes:
#   1. Regular  -- runs automatically on push/MR, one default model per suite
#   2. Dynamic  -- manual play-button, discovers Ollama nodes on the network,
#                  enumerates models, and runs every (node, model, suite) combo
#   3. Schedule -- hourly cron trigger runs the dynamic pipeline automatically
#
# All modes are generated from config/test_suites.yaml via
# scripts/generate_pipeline.py so test-suite definitions stay DRY.

stages:
  - sync
  - lint
  - generate
  - test
  - report
  - deploy
  - review

variables:
  # Ollama configuration
  OLLAMA_ENDPOINT: "http://localhost:11434"
  DEFAULT_MODEL: "llama3"

  # Test configuration
  ROBOT_OPTIONS: "--metadata CI:true --metadata GitLab_URL:$CI_PROJECT_URL --metadata Commit_SHA:$CI_COMMIT_SHA"

  # Database for test result archiving
  # Set DATABASE_URL in GitLab CI/CD variables to archive to PostgreSQL.
  # When unset the DbListener archives to local SQLite automatically.
  # DATABASE_URL: "postgresql://rfc:rfc@postgres:5432/rfc"


# =============================================================================
# SYNC STAGE - Syncs repos so all CI runs
# =============================================================================
mirror-to-github:
  stage: sync
  rules:
    - if: $CI_PIPELINE_SOURCE == "push"
    - when: manual
  script:
    - git clone --mirror "$CI_REPOSITORY_URL" repo.git
    - cd repo.git
    - git remote add github "https://${GITHUB_USER}:${GITHUB_TOKEN}@github.com/${GITHUB_USER}/${CI_PROJECT_NAME}.git"
    - git push github --mirror --force

# =============================================================================
# LINT STAGE - Uses tools already installed on runner
# =============================================================================

pre-commit:
  stage: lint
  before_script:
    - uv sync --extra dev
  script:
    - uv run pre-commit run --all-files
  rules:
    - if: $CI_PIPELINE_SOURCE == "merge_request_event"
    - if: $CI_COMMIT_BRANCH == $CI_DEFAULT_BRANCH
    - if: $CI_COMMIT_BRANCH
  allow_failure: true

ruff-check:
  stage: lint
  before_script:
    - uv sync --extra dev
  script:
    - uv run ruff check .
    - uv run ruff format --check .
  rules:
    - if: $CI_PIPELINE_SOURCE == "merge_request_event"
    - if: $CI_COMMIT_BRANCH == $CI_DEFAULT_BRANCH
  allow_failure: true

mypy-check:
  stage: lint
  before_script:
    - uv sync --extra dev
  script:
    - uv run mypy src/
  rules:
    - if: $CI_PIPELINE_SOURCE == "merge_request_event"
    - if: $CI_COMMIT_BRANCH == $CI_DEFAULT_BRANCH
  allow_failure: true

# =============================================================================
# GENERATE STAGE
#
# Reads config/test_suites.yaml and produces child-pipeline YAML.
# Two jobs: one for the regular (automatic) pipeline, one for the
# dynamic (manual) Ollama-discovery pipeline.
# =============================================================================

generate-regular-pipeline:
  stage: generate
  before_script:
    - uv sync --extra dev
  script:
    - uv run python scripts/generate_pipeline.py --mode regular -o generated-pipeline.yml
    - cat generated-pipeline.yml
  artifacts:
    paths:
      - generated-pipeline.yml
  rules:
    - if: $CI_COMMIT_BRANCH
    - if: $CI_PIPELINE_SOURCE == "merge_request_event"

# Dynamic Ollama discovery -- manual play button or hourly schedule
#
# Set OLLAMA_NODES (comma-separated host:port) or OLLAMA_SUBNET (CIDR)
# in GitLab CI/CD variables to control which nodes are scanned.
# When neither is set the script falls back to localhost:11434.
generate-dynamic-pipeline:
  stage: generate
  allow_failure: true
  timeout: 60 minutes
  before_script:
    - uv sync --extra dev
  script:
    - echo "Discovering Ollama nodes..."
    - uv run python scripts/discover_ollama.py --pretty
    - uv run python scripts/generate_pipeline.py --mode dynamic -o generated-dynamic-pipeline.yml
    - cat generated-dynamic-pipeline.yml
  artifacts:
    paths:
      - generated-dynamic-pipeline.yml
  rules:
    - if: $CI_PIPELINE_SOURCE == "schedule"
    - when: manual
      allow_failure: true

# =============================================================================
# TEST STAGE - child pipelines generated above
#
# Every robot run attaches both listeners:
#   - DbListener:          archives per-suite results to PostgreSQL or SQLite
#   - CiMetadataListener:  adds CI context to Robot Framework output
#
# The child pipeline YAML is self-contained (test + report stages).
# =============================================================================

run-regular-tests:
  stage: test
  needs:
    - job: generate-regular-pipeline
      artifacts: true
  trigger:
    include:
      - artifact: generated-pipeline.yml
        job: generate-regular-pipeline
    strategy: depend
  rules:
    - if: $CI_COMMIT_BRANCH
    - if: $CI_PIPELINE_SOURCE == "merge_request_event"

run-dynamic-tests:
  stage: test
  needs:
    - job: generate-dynamic-pipeline
      artifacts: true
  trigger:
    include:
      - artifact: generated-dynamic-pipeline.yml
        job: generate-dynamic-pipeline
    strategy: depend
  rules:
    - if: $CI_PIPELINE_SOURCE == "schedule"
    - when: manual
      allow_failure: true
  allow_failure: true

# =============================================================================
# REPORT STAGE - Repo metrics (lines of code / filesize timeline)
#
# Samples commits across the repo history, counts lines and file sizes
# by type (.py, .robot, other), and generates a timeline plot.
# Posts a Markdown summary as an MR comment when GITLAB_TOKEN is set.
# =============================================================================

repo-metrics:
  stage: report
  needs: []          # no dependencies -- start immediately
  before_script:
    - uv sync
    - uv pip install matplotlib
  script:
    - uv run python scripts/repo_metrics.py -o metrics
    # Post summary as MR note (requires GITLAB_TOKEN with api scope)
    - |
      if [ -n "$CI_MERGE_REQUEST_IID" ] && [ -n "$GITLAB_TOKEN" ]; then
        curl --fail --request POST \
          --header "PRIVATE-TOKEN: $GITLAB_TOKEN" \
          "$CI_API_V4_URL/projects/$CI_PROJECT_ID/merge_requests/$CI_MERGE_REQUEST_IID/notes" \
          --data-urlencode "body@metrics/summary.md" \
          && echo "MR comment posted." \
          || echo "Warning: could not post MR comment."
      fi
  artifacts:
    paths:
      - metrics/
    expire_in: 30 days
  rules:
    - if: $CI_PIPELINE_SOURCE == "merge_request_event"
    - if: $CI_COMMIT_BRANCH == $CI_DEFAULT_BRANCH

# =============================================================================
# DEPLOY STAGE - Deploy / update Superset stack
#
# Runs only on the default branch when SUPERSET_DEPLOY_HOST is configured.
# Requires a runner with SSH access to the deploy target.
# =============================================================================

deploy-superset:
  stage: deploy
  rules:
    - if: $CI_COMMIT_BRANCH == $CI_DEFAULT_BRANCH && $SUPERSET_DEPLOY_HOST
  script:
    - |
      echo "Deploying Superset stack to $SUPERSET_DEPLOY_HOST ..."
      ssh "$SUPERSET_DEPLOY_USER@$SUPERSET_DEPLOY_HOST" \
        "cd $SUPERSET_DEPLOY_PATH && git pull && docker compose -f docker-compose.yml up -d --pull always"
  allow_failure: true

# =============================================================================
# REVIEW STAGE - AI code review & fix using Claude Code (Opus 4.6)
#
# Runs AFTER all other stages so it can inspect pipeline failures.
# Triggered when:
#   - MR has the "claude-code-review" label
#   - Manual play-button click
#
# Requires:
#   - ANTHROPIC_API_KEY in GitLab CI/CD variables
#   - GITLAB_TOKEN (api scope) for posting MR comments and reading job logs
#   - Runner tagged "nodejs" with Node.js 18+ installed
#
# The job does two things:
#   1. Checks for failed jobs in the pipeline and attempts to fix them
#   2. Reviews the MR diff against ai/AGENTS.md and ai/REFACTOR.md
# =============================================================================

claude-code-review:
  stage: review
  tags:
    - nodejs
  rules:
    - if: $CI_PIPELINE_SOURCE == "merge_request_event" && $CI_MERGE_REQUEST_LABELS =~ /claude-code-review/
    - when: manual
      allow_failure: true
  variables:
    CLAUDE_MODEL: "claude-opus-4-6"
  before_script:
    - npm install -g @anthropic-ai/claude-code
  script:
    - |
      echo "=== Claude Code Review & Fix ==="
      echo "Model: ${CLAUDE_MODEL}"
      echo "Pipeline: ${CI_PIPELINE_ID}"
      echo ""

      # ------------------------------------------------------------------
      # Phase 1: Detect and attempt to fix pipeline failures
      # ------------------------------------------------------------------
      FAILURE_CONTEXT=""

      if [ -n "$GITLAB_TOKEN" ]; then
        echo "--- Phase 1: Checking pipeline for failures ---"

        # Query all failed jobs in this pipeline (exclude this review job)
        FAILED_JOBS_JSON=$(curl --silent --header "PRIVATE-TOKEN: ${GITLAB_TOKEN}" \
          "${CI_API_V4_URL}/projects/${CI_PROJECT_ID}/pipelines/${CI_PIPELINE_ID}/jobs?scope=failed&per_page=50")

        FAILED_COUNT=$(echo "$FAILED_JOBS_JSON" | python3 -c "
      import json, sys
      jobs = json.load(sys.stdin)
      # Exclude this review job itself
      failed = [j for j in jobs if j.get('name') != 'claude-code-review']
      print(len(failed))
      " 2>/dev/null || echo "0")

        echo "Failed jobs (excluding review): ${FAILED_COUNT}"

        if [ "$FAILED_COUNT" -gt "0" ]; then
          echo "Collecting failure logs..."

          # Collect logs from each failed job
          FAILURE_CONTEXT="The following pipeline jobs FAILED. Analyze the logs and attempt to fix the root causes.

      "
          FAILED_JOB_IDS=$(echo "$FAILED_JOBS_JSON" | python3 -c "
      import json, sys
      jobs = json.load(sys.stdin)
      for j in jobs:
          if j.get('name') != 'claude-code-review':
              print(f\"{j['id']}|{j['name']}|{j.get('stage', 'unknown')}\")
      " 2>/dev/null || true)

          while IFS='|' read -r JOB_ID JOB_NAME JOB_STAGE; do
            [ -z "$JOB_ID" ] && continue
            echo "  Fetching log for: ${JOB_NAME} (job ${JOB_ID}, stage ${JOB_STAGE})"

            JOB_LOG=$(curl --silent --header "PRIVATE-TOKEN: ${GITLAB_TOKEN}" \
              "${CI_API_V4_URL}/projects/${CI_PROJECT_ID}/jobs/${JOB_ID}/trace" \
              | tail -200)

            FAILURE_CONTEXT="${FAILURE_CONTEXT}
      --- FAILED JOB: ${JOB_NAME} (stage: ${JOB_STAGE}) ---
      ${JOB_LOG}
      --- END JOB LOG ---
      "
          done <<< "$FAILED_JOB_IDS"

          # Ask Claude to analyze failures and produce fixes
          echo ""
          echo "Running Claude Code to analyze and fix failures..."

          FIX_RESULT=$(claude --model "${CLAUDE_MODEL}" --print \
            "You are a CI/CD engineer for the robotframework-chat project.
      Read the project guidelines in ai/AGENTS.md and ai/REFACTOR.md.

      The following pipeline jobs have failed. Analyze the failure logs below
      and produce a concrete fix for each failure.

      For each failure, output:
      1. Which job failed and why (root cause, not just the symptom)
      2. The file(s) that need to change
      3. A unified diff (patch) that fixes the issue

      Format each patch as:
      \`\`\`diff
      --- a/path/to/file
      +++ b/path/to/file
      @@ ... @@
       context
      -old line
      +new line
       context
      \`\`\`

      If a failure is environmental (missing service, network timeout, runner
      misconfiguration) and cannot be fixed by code changes, say so and skip
      the patch.

      ${FAILURE_CONTEXT}")

          echo "${FIX_RESULT}" > claude-fix-attempt.md
          echo "--- Fix analysis complete ---"
          cat claude-fix-attempt.md

          # Extract and apply any patches Claude produced
          echo ""
          echo "Attempting to apply patches..."
          python3 - "$FIX_RESULT" <<'PYEOF'
      import re, subprocess, sys

      text = sys.argv[1] if len(sys.argv) > 1 else ""
      # Find all ```diff ... ``` blocks
      patches = re.findall(r'```diff\n(.*?)```', text, re.DOTALL)

      if not patches:
          print("No patches found in Claude output.")
          sys.exit(0)

      applied = 0
      for i, patch in enumerate(patches, 1):
          patch_file = f"claude-patch-{i}.diff"
          with open(patch_file, "w") as f:
              f.write(patch)
          result = subprocess.run(
              ["git", "apply", "--check", patch_file],
              capture_output=True, text=True
          )
          if result.returncode == 0:
              subprocess.run(["git", "apply", patch_file], check=True)
              print(f"  Patch {i}: applied successfully")
              applied += 1
          else:
              print(f"  Patch {i}: cannot apply cleanly -- {result.stderr.strip()}")

      if applied > 0:
          print(f"\n{applied} patch(es) applied. Committing fix...")
          subprocess.run(["git", "add", "-A"], check=True)
          subprocess.run(
              ["git", "commit", "-m", "fix: auto-fix pipeline failures (Claude Code)"],
              check=True
          )
          branch = subprocess.run(
              ["git", "rev-parse", "--abbrev-ref", "HEAD"],
              capture_output=True, text=True, check=True
          ).stdout.strip()
          push = subprocess.run(
              ["git", "push", "origin", branch],
              capture_output=True, text=True
          )
          if push.returncode == 0:
              print(f"Fix pushed to {branch}")
          else:
              print(f"Push failed: {push.stderr.strip()}")
      else:
          print("No patches could be applied.")
      PYEOF

        else
          echo "No failed jobs detected -- skipping fix phase."
        fi
      else
        echo "GITLAB_TOKEN not set -- skipping failure detection."
      fi

      # ------------------------------------------------------------------
      # Phase 2: Code review of the MR diff
      # ------------------------------------------------------------------
      echo ""
      echo "--- Phase 2: Code review ---"

      if [ -z "$CI_MERGE_REQUEST_IID" ]; then
        echo "Not running in an MR context -- skipping diff review."
        exit 0
      fi

      git fetch origin "${CI_MERGE_REQUEST_TARGET_BRANCH_NAME}"
      DIFF=$(git diff "origin/${CI_MERGE_REQUEST_TARGET_BRANCH_NAME}...HEAD")

      if [ -z "$DIFF" ]; then
        echo "No changes detected -- skipping review."
        exit 0
      fi

      AGENTS_MD=$(cat ai/AGENTS.md)
      REFACTOR_MD=$(cat ai/REFACTOR.md)

      REVIEW=$(claude --model "${CLAUDE_MODEL}" --print \
        "You are a senior code reviewer for the robotframework-chat project.

      Review the following merge request diff. Follow the project guidelines
      strictly:

      --- BEGIN ai/AGENTS.md ---
      ${AGENTS_MD}
      --- END ai/AGENTS.md ---

      --- BEGIN ai/REFACTOR.md ---
      ${REFACTOR_MD}
      --- END ai/REFACTOR.md ---

      Review criteria (in priority order):
      1. Correctness: broken tests, logic errors, data loss potential
      2. Security: credential exposure, injection, path traversal
      3. Architecture: adherence to module responsibilities and project structure
      4. Code style: naming, type annotations, Robot Framework syntax conventions
      5. Test coverage: new behavior must have corresponding tests
      6. Commit discipline: atomic commits, proper type prefixes

      For each issue found, state:
      - Severity (must-fix / should-fix / consider)
      - File and approximate location
      - What is wrong and why
      - Suggested fix

      If the diff looks good, say so briefly. Do not invent issues.

      --- BEGIN DIFF ---
      ${DIFF}
      --- END DIFF ---")

      echo "${REVIEW}" > claude-review.md
      echo "--- Review complete ---"
      cat claude-review.md

      # ------------------------------------------------------------------
      # Phase 3: Post results as MR comment
      # ------------------------------------------------------------------
      if [ -n "$GITLAB_TOKEN" ] && [ -n "$CI_MERGE_REQUEST_IID" ]; then
        echo ""
        echo "--- Posting review to MR ---"

        # Build comment body from available outputs
        FIX_SECTION=""
        if [ -f claude-fix-attempt.md ]; then
          FIX_CONTENT=$(cat claude-fix-attempt.md)
          FIX_SECTION="
      <details>
      <summary>Pipeline fix attempt</summary>

      ${FIX_CONTENT}

      </details>
      "
        fi

        COMMENT_BODY=$(cat <<REVIEW_EOF
      ## Claude Code Review (Opus 4.6)

      <details>
      <summary>Code review of MR !${CI_MERGE_REQUEST_IID}</summary>

      ${REVIEW}

      </details>
      ${FIX_SECTION}
      ---
      *Review generated by Claude Code (\`${CLAUDE_MODEL}\`) following [ai/AGENTS.md](ai/AGENTS.md) and [ai/REFACTOR.md](ai/REFACTOR.md)*
      REVIEW_EOF
      )

        curl --fail --request POST \
          --header "PRIVATE-TOKEN: ${GITLAB_TOKEN}" \
          "${CI_API_V4_URL}/projects/${CI_PROJECT_ID}/merge_requests/${CI_MERGE_REQUEST_IID}/notes" \
          --data-urlencode "body=${COMMENT_BODY}" \
          && echo "Review posted to MR." \
          || echo "Warning: could not post review comment to MR."
      else
        echo "GITLAB_TOKEN or MR context not available -- review saved as artifact only."
      fi
  artifacts:
    paths:
      - claude-review.md
      - claude-fix-attempt.md
      - claude-patch-*.diff
    expire_in: 30 days
    when: always
  allow_failure: true
