# GitLab CI/CD Pipeline for robotframework-chat
# Works with shell executor on any OS (macOS, Linux)
# Assumes tools are pre-installed on runner
#
# Three pipeline modes:
#   1. Regular  -- runs automatically on push/MR, one default model per suite
#   2. Dynamic  -- manual play-button, discovers Ollama nodes on the network,
#                  enumerates models, and runs every (node, model, suite) combo
#   3. Schedule -- hourly cron trigger runs the dynamic pipeline automatically
#
# All modes are generated from config/test_suites.yaml via
# scripts/generate_pipeline.py so test-suite definitions stay DRY.

stages:
  - sync
  - lint
  - generate
  - test
  - report
  - deploy

variables:
  # Ollama configuration
  OLLAMA_ENDPOINT: "http://localhost:11434"
  DEFAULT_MODEL: "llama3"

  # Test configuration
  ROBOT_OPTIONS: "--metadata CI:true --metadata GitLab_URL:$CI_PROJECT_URL --metadata Commit_SHA:$CI_COMMIT_SHA"

  # Database for test result archiving
  # Set DATABASE_URL in GitLab CI/CD variables to archive to PostgreSQL.
  # When unset the DbListener archives to local SQLite automatically.
  # DATABASE_URL: "postgresql://rfc:rfc@postgres:5432/rfc"


# =============================================================================
# SYNC STAGE - Syncs repos so all CI runs
# =============================================================================
mirror-to-github:
  stage: sync
  rules:
    - if: $CI_PIPELINE_SOURCE == "push"
    - when: manual
  script:
    - git clone --mirror "$CI_REPOSITORY_URL" repo.git
    - cd repo.git
    - git remote add github "https://${GITHUB_USER}:${GITHUB_TOKEN}@github.com/${GITHUB_USER}/${CI_PROJECT_NAME}.git"
    - git push github --mirror --force

# =============================================================================
# LINT STAGE - Uses tools already installed on runner
# =============================================================================

pre-commit:
  stage: lint
  before_script:
    - uv sync --extra dev
  script:
    - uv run pre-commit run --all-files
  rules:
    - if: $CI_PIPELINE_SOURCE == "merge_request_event"
    - if: $CI_COMMIT_BRANCH == $CI_DEFAULT_BRANCH
    - if: $CI_COMMIT_BRANCH
  allow_failure: true

ruff-check:
  stage: lint
  before_script:
    - uv sync --extra dev
  script:
    - uv run ruff check .
    - uv run ruff format --check .
  rules:
    - if: $CI_PIPELINE_SOURCE == "merge_request_event"
    - if: $CI_COMMIT_BRANCH == $CI_DEFAULT_BRANCH
  allow_failure: true

mypy-check:
  stage: lint
  before_script:
    - uv sync --extra dev
  script:
    - uv run mypy src/
  rules:
    - if: $CI_PIPELINE_SOURCE == "merge_request_event"
    - if: $CI_COMMIT_BRANCH == $CI_DEFAULT_BRANCH
  allow_failure: true

# =============================================================================
# GENERATE STAGE
#
# Reads config/test_suites.yaml and produces child-pipeline YAML.
# Two jobs: one for the regular (automatic) pipeline, one for the
# dynamic (manual) Ollama-discovery pipeline.
# =============================================================================

generate-regular-pipeline:
  stage: generate
  before_script:
    - uv sync --extra dev
  script:
    - uv run python scripts/generate_pipeline.py --mode regular -o generated-pipeline.yml
    - cat generated-pipeline.yml
  artifacts:
    paths:
      - generated-pipeline.yml
  rules:
    - if: $CI_COMMIT_BRANCH
    - if: $CI_PIPELINE_SOURCE == "merge_request_event"

# Dynamic Ollama discovery -- manual play button or hourly schedule
#
# Set OLLAMA_NODES (comma-separated host:port) or OLLAMA_SUBNET (CIDR)
# in GitLab CI/CD variables to control which nodes are scanned.
# When neither is set the script falls back to localhost:11434.
generate-dynamic-pipeline:
  stage: generate
  allow_failure: true
  timeout: 60 minutes
  before_script:
    - uv sync --extra dev
  script:
    - echo "Discovering Ollama nodes..."
    - uv run python scripts/discover_ollama.py --pretty
    - uv run python scripts/generate_pipeline.py --mode dynamic -o generated-dynamic-pipeline.yml
    - cat generated-dynamic-pipeline.yml
  artifacts:
    paths:
      - generated-dynamic-pipeline.yml
  rules:
    - if: $CI_PIPELINE_SOURCE == "schedule"
    - when: manual
      allow_failure: true

# =============================================================================
# TEST STAGE - child pipelines generated above
#
# Every robot run attaches both listeners:
#   - DbListener:          archives per-suite results to PostgreSQL or SQLite
#   - CiMetadataListener:  adds CI context to Robot Framework output
#
# The child pipeline YAML is self-contained (test + report stages).
# =============================================================================

run-regular-tests:
  stage: test
  needs:
    - job: generate-regular-pipeline
      artifacts: true
  trigger:
    include:
      - artifact: generated-pipeline.yml
        job: generate-regular-pipeline
    strategy: depend
  rules:
    - if: $CI_COMMIT_BRANCH
    - if: $CI_PIPELINE_SOURCE == "merge_request_event"

run-dynamic-tests:
  stage: test
  needs:
    - job: generate-dynamic-pipeline
      artifacts: true
  trigger:
    include:
      - artifact: generated-dynamic-pipeline.yml
        job: generate-dynamic-pipeline
    strategy: depend
  rules:
    - if: $CI_PIPELINE_SOURCE == "schedule"
    - when: manual
      allow_failure: true
  allow_failure: true

# =============================================================================
# REPORT STAGE - Repo metrics (lines of code / filesize timeline)
#
# Samples commits across the repo history, counts lines and file sizes
# by type (.py, .robot, other), and generates a timeline plot.
# Posts a Markdown summary as an MR comment when GITLAB_TOKEN is set.
# =============================================================================

repo-metrics:
  stage: report
  needs: []          # no dependencies -- start immediately
  before_script:
    - uv sync
    - uv pip install matplotlib
  script:
    - uv run python scripts/repo_metrics.py -o metrics
    # Post summary as MR note (requires GITLAB_TOKEN with api scope)
    - |
      if [ -n "$CI_MERGE_REQUEST_IID" ] && [ -n "$GITLAB_TOKEN" ]; then
        curl --fail --request POST \
          --header "PRIVATE-TOKEN: $GITLAB_TOKEN" \
          "$CI_API_V4_URL/projects/$CI_PROJECT_ID/merge_requests/$CI_MERGE_REQUEST_IID/notes" \
          --data-urlencode "body@metrics/summary.md" \
          && echo "MR comment posted." \
          || echo "Warning: could not post MR comment."
      fi
  artifacts:
    paths:
      - metrics/
    expire_in: 30 days
  rules:
    - if: $CI_PIPELINE_SOURCE == "merge_request_event"
    - if: $CI_COMMIT_BRANCH == $CI_DEFAULT_BRANCH

# =============================================================================
# DEPLOY STAGE - Deploy / update Superset stack
#
# Runs only on the default branch when SUPERSET_DEPLOY_HOST is configured.
# Requires a runner with SSH access to the deploy target.
# =============================================================================

deploy-superset:
  stage: deploy
  rules:
    - if: $CI_COMMIT_BRANCH == $CI_DEFAULT_BRANCH && $SUPERSET_DEPLOY_HOST
  script:
    - |
      echo "Deploying Superset stack to $SUPERSET_DEPLOY_HOST ..."
      ssh "$SUPERSET_DEPLOY_USER@$SUPERSET_DEPLOY_HOST" \
        "cd $SUPERSET_DEPLOY_PATH && git pull && docker compose -f docker-compose.yml up -d --pull always"
  allow_failure: true
